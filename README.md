# University-Machine-learning

### Евдокимов Филипп, СПбАУ РАН им. Ж.И. Алфёрова, группа 402, 2025 г.

## Отчёт по лабораторной работе  
**Тема:** Классические методы машинного обучения.

---

## 1. Постановка задачи
- **Задача:** трёхклассовая классификация изображений (классы `down`, `one`, `up`).  
- **Датасет:** набор изображений (скриншотов) трёх поз/жестов персонажа из видеоигры [Night in the Woods](http://www.nightinthewoods.com).
- **Примеры файлов ДО предобработки и аугментаций:**

| Класс `down` | Класс `one` | Класс `up` |
|:---:|:---:|:---:|
| руки опущены вниз | поднята только одна рука | руки подняты вверх |
| файл `dataset/raw/down_1.jpeg` | файл `dataset/raw/one_7.jpeg` | файл `dataset/raw/up_2.jpeg` |
| ![](dataset/raw/down_1.jpeg) | ![](dataset/raw/one_7.jpeg) | ![](dataset/raw/up_2.jpeg)  |

- **Методы, изученные в работе:**
	- аугментация данных, 
	- kNN, 
	- SVM, 
	- Random Forest (RF).

---

## 2. Подготовка датасета (частично относится к заданию 3 — аугментация)
- **Аугментации** (набор трансформаций для 2D-изображений): использована библиотека [**MONAI**](https://monai-dev.readthedocs.io/en/latest/index.html). В финальной версии применялись более мягкие/контролируемые аугментации:
  - горизонтальный/вертикальный флип,
  - небольшой поворот (±15°),
  - локальный зум,
  - лёгкий гауссов шум / размытие / резкость,
  - контраст/гистограмма, случайное выбрасывание пикселей.

- **Предобработка:** все изображения приводятся к квадратному виду и единому размеру (256×256) с сохранением соотношения сторон и добавлением паддинга (отступа вокруг изображения) — для того, чтобы признаки (HOG, Hu, HSV) были вычислимы в однотипном пространстве признаков и масштаб признаков не зависел от исходного размера.

- **Команды (pipeline):**
  1. Аугментация:
	 ```
	 python3 scripts/augment.py --input_dir dataset/raw --output_dir dataset/raw --num_aug 9
	 ```
  2. Предобработка (resize + padding → processed):
     ```
     python3 scripts/preprocess.py --raw_dir dataset/raw --output_dir dataset/processed --img_size 256
     ```
  3. (Ручной шаг) часть файлов из `dataset/processed/train` была перемещена в `dataset/processed/test`, чтобы получить итоговый небольшой тестовый набор (`preprocess.py` автоматически добавляет обработанные файлы из `dataset/raw` в `dataset/processed/train`).

- **Примеры файлов ПОСЛЕ предобработки и аугментаций:**

| Класс `down` | Класс `one` | Класс `up` |
|:---:|:---:|:---:|
| руки опущены вниз | поднята только одна рука | руки подняты вверх |
| файл `dataset/processed/train/down/down_1_aug7_proc256.jpeg` | файл `dataset/processed/train/one/one_7_aug9_proc256.jpeg` | файл `dataset/processed/train/up/up_2_aug2_proc256.jpeg` |
| ![](dataset/processed/train/down/down_1_aug7_proc256.jpeg) | ![](dataset/processed/train/one/one_7_aug9_proc256.jpeg) | ![](dataset/processed/train/up/up_2_aug2_proc256.jpeg)  |

---

## 3. Задача 1 — сравнение методов kNN и SVM

### Описание методов:

- **kNN (k-Nearest Neighbors):**  
  Простейший метод классификации, основанный на предположении, что объекты одного класса расположены близко друг к другу в пространстве признаков.  
  Для нового изображения вычисляются расстояния до всех обучающих примеров, после чего класс определяется по большинству среди `k` ближайших соседей.  
  Основной гиперпараметр — `k` (число соседей): при малых `k` модель чувствительна к шуму, при больших — может терять локальные особенности данных.

- **SVM (Support Vector Machine, метод опорных векторов):**  
  Метод строит разделяющую гиперплоскость между классами таким образом, чтобы максимизировать зазор (margin) между ними.  
  В случае использования RBF-ядра модель способна строить **нелинейные** границы решений в пространстве признаков.  
  Ключевые гиперпараметры:
  - `C` — коэффициент регуляризации, определяющий баланс между точностью на обучении и обобщающей способностью;
  - `gamma` — параметр RBF-ядра, определяющий радиус влияния отдельных объектов (малые значения делают границу более гладкой, большие — более сложной).

### Используемые признаки изображений:

Для перехода от изображений к классическим методам машинного обучения вычислялись следующие признаки:

- **HOG (Histogram of Oriented Gradients):**  
  Описывает локальную структуру изображения через распределение направлений градиентов яркости.  
  Эффективен для задач распознавания форм и поз, так как устойчив к изменениям освещения и фона.

- **Моменты Ху (Hu Moments):**  
  Набор из семи чисел, инвариантных к повороту, масштабированию и сдвигу изображения.  
  Используются для грубого описания формы объекта.

- **HSV-гистограммы:**  
  Цветовое представление изображения в пространстве Hue–Saturation–Value.  
  Позволяет учитывать цветовые характеристики изображения, которые могут быть полезны для различения классов.

Все перечисленные признаки объединяются в один общий вектор, который далее используется в качестве входных данных для алгоритмов классификации.

### Оценка качества моделей:

Использовалась **5-кратная стратифицированная кросс-валидация** (5-fold Stratified Cross-Validation):

- Обучающая выборка разбивается на 5 частей так, чтобы доли классов в каждом разбиении сохранялись.  
- Модель обучается 5 раз, каждый раз одна часть используется для проверки качества, а остальные — для обучения.  
- Итоговая оценка accuracy вычисляется как среднее значение по всем пяти запускам, что позволяет получить более надёжную оценку качества модели.

### Реализация:
- Библиотека: [scikit-learn](https://scikit-learn.org/stable/index.html).
- В коде (`train.py`):
	- kNN:

	```
	from sklearn.neighbors import KNeighborsClassifier
	
	KNeighborsClassifier(n_neighbors=5)
	```

	- SVM: 

	```
	from sklearn.svm import SVC
	
	SVC(kernel="rbf", C=1.0, gamma="scale")
	```

- Команды запуска (pipeline):

	```bash
   python3 scripts/train.py --data_dir datasets/processed/train --models_dir models
   python3 scripts/test.py  --data_dir datasets/processed/test  --models_dir models --out_dir reports
	```
  
### Результаты (на финальном датасете из репозитория):

- kNN CV accuracy: ≈ 0.810  
- SVM CV accuracy: ≈ 0.952  
  (Подробнее — в разделе “Итоги” и в выводе в консоль ниже.)

---

## 4. Задача 3 — добавление метода Random Forest (RF)

### Описание метода:
**Random Forest (RF):**  
Ансамблевый метод машинного обучения, основанный на построении множества решающих деревьев:  

- Каждое дерево обучается на случайной подвыборке обучающих данных (бутстреп-выборке), а при каждом разбиении узла используется случайное подмножество признаков.  
- Итоговое решение принимается голосованием всех деревьев, что позволяет существенно снизить переобучение по сравнению с одиночным деревом решений.

Основные гиперпараметры:

- `n_estimators` — количество деревьев в ансамбле (чем больше, тем стабильнее модель, но тем выше вычислительная стоимость);
- `class_weight` — веса классов, используемые для компенсации возможного дисбаланса данных;
- `random_state` — фиксирует начальное состояние генератора случайных чисел, чем обеспечивает воспроизводимость результатов обучения (модель будет строить одни и те же бутстреп-выборки и одинаковые деревья).

### Реализация:
- Библиотека: [scikit-learn](https://scikit-learn.org/stable/index.html).
- В коде (`train.py`):

	```
	from sklearn.ensemble import RandomForestClassifier
	
	RandomForestClassifier(n_estimators=100, class_weight="balanced", random_state=42)
	```

- Команды запуска (pipeline) — тот же, что и в разделе 3.

### Результаты (на финальном датасете из репозитория):

RF показал наилучшие результаты на тренировочной выборке и близкие лучшие результаты на тестовой (в ряде запусков RF и SVM дают примерно одинаковую высокую точность ≈ 0.952).

---

## 5. Итоговые результаты

### Вывод:

- Random Forest (RF) продемонстрировал наилучшее качество классификации среди рассмотренных методов, допустив минимальное число ошибок на тестовой выборке.  
- SVM даёт такие же высокие показатели на тестовой выборке, лишь немного уступая на тренировочной.
- kNN уступает, но остаётся полезным как простой baseline.

### Конкретные результаты:

- **Пример CSV** с предсказаниями моделей для тестовой выборки (`reports/test_predictions.csv`):

| filename | true\_label | pred\_kNN | pred\_SVM | pred\_RandomForest |
| --: | :-- | :-- | :-- | :-- |
| down\_1\_aug1\_proc256\.jpeg | down | down | down | down |
| down\_2\_aug1\_proc256\.jpeg | down | down | down | down |
| down\_3\_aug1\_proc256\.jpeg | down | down | down | down |
| down\_4\_aug1\_proc256\.jpeg | down | down | down | down |
| down\_5\_aug1\_proc256\.jpeg | down | down | down | down |
| down\_6\_aug1\_proc256\.jpeg | down | down | down | down |
| down\_7\_aug1\_proc256\.jpeg | down | down | down | down |
| one\_1\_aug1\_proc256\.jpeg | one | one | one | one |
| one\_2\_aug1\_proc256\.jpeg | one | down | one | one |
| one\_3\_aug1\_proc256\.jpeg | one | one | one | one |
| one\_4\_aug1\_proc256\.jpeg | one | down | down | down |
| one\_5\_aug1\_proc256\.jpeg | one | one | one | one |
| one\_6\_aug1\_proc256\.jpeg | one | one | one | one |
| one\_7\_aug1\_proc256\.jpeg | one | one | one | one |
| up\_1\_aug1\_proc256\.jpeg | up | up | up | up |
| up\_2\_aug1\_proc256\.jpeg | up | up | up | up |
| up\_3\_aug1\_proc256\.jpeg | up | up | up | up |
| up\_4\_aug1\_proc256\.jpeg | up | up | up | up |
| up\_5\_aug1\_proc256\.jpeg | up | one | up | up |
| up\_6\_aug1\_proc256\.jpeg | up | down | up | up |
| up\_7\_aug1\_proc256\.jpeg | up | up | up | up |

- **Вывод в консоль** оценок точности моделей на тренировочной выборке:

```
$ python3 scripts/train.py --data_dir dataset/processed/train --models_dir models

Loaded 189 images for training, classes: ['down', 'one', 'up']
Feature matrix shape: (189, 51391)
kNN CV accuracy: mean=0.793, std=0.037
SVM CV accuracy: mean=0.931, std=0.039
RandomForest CV accuracy: mean=0.942, std=0.036
```

- **Вывод в консоли** оценок точности моделей на тестовой выборке:

```
$ python3 scripts/test.py --data_dir dataset/processed/test --models_dir models --out_dir reports

Loaded 21 test images, classes: ['down', 'one', 'up']
kNN test accuracy: 0.810
Pred counts: Counter({np.str_('down'): 10, np.str_('one'): 6, np.str_('up'): 5})
              precision    recall  f1-score   support

        down      0.700     1.000     0.824         7
         one      0.833     0.714     0.769         7
          up      1.000     0.714     0.833         7

    accuracy                          0.810        21
   macro avg      0.844     0.810     0.809        21
weighted avg      0.844     0.810     0.809        21

SVM test accuracy: 0.952
Pred counts: Counter({np.str_('down'): 8, np.str_('up'): 7, np.str_('one'): 6})
              precision    recall  f1-score   support

        down      0.875     1.000     0.933         7
         one      1.000     0.857     0.923         7
          up      1.000     1.000     1.000         7

    accuracy                          0.952        21
   macro avg      0.958     0.952     0.952        21
weighted avg      0.958     0.952     0.952        21

RandomForest test accuracy: 0.952
Pred counts: Counter({np.str_('down'): 8, np.str_('up'): 7, np.str_('one'): 6})
              precision    recall  f1-score   support

        down      0.875     1.000     0.933         7
         one      1.000     0.857     0.923         7
          up      1.000     1.000     1.000         7

    accuracy                          0.952        21
   macro avg      0.958     0.952     0.952        21
weighted avg      0.958     0.952     0.952        21
```

---

## 6. Недостатки и ограничения

- **Небольшой размер датасета:**  
  Несмотря на аугментацию, исходное количество уникальных изображений ограничено, что может приводить к переобучению и нестабильной оценке качества на тестовой выборке.

- **Высокая размерность пространства признаков:**  
  Использование HOG приводит к формированию очень длинных векторов признаков (десятки тысяч компонент), что:
  - увеличивает время обучения,
  - может ухудшать обобщающую способность моделей,
  - делает модели чувствительными к шуму.

- **Ограниченность признаков:**  
  HOG, Hu и HSV не всегда способны полностью описать сложные визуальные паттерны, особенно при изменении поз, масштаба или перспективы.

- **Попытка подбора гиперпараметров с помощью Optuna:**  
  В рамках эксперимента был выполнен автоматический подбор гиперпараметров для RandomForest, однако:
  1. качество на тестовой выборке ухудшилось (accuracy ≈ 0.5),
  2. время подбора оказалось слишком большим (≈ 2 ч 45 мин на 80 итераций).  
  Это указывает на чувствительность метода к стратегии валидации и необходимость более аккуратной настройки процесса оптимизации.

- **Отсутствие понижения размерности:**  
  В работе не применялись методы снижения размерности (например, PCA), которые могли бы уменьшить шум в данных, ускорить обучение моделей и потенциально повысить качество классификации.